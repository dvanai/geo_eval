Preferred single-script pipeline:
1) geo_pipeline.py

Legacy scripts (still available):
1) geo_automated_prompt_response.py
2) cleaning_prod.py
3) judge_prod.py

Environment variables required:
- `OPENAI_API_KEY` (for ChatGPT + judge)
- `GEMINI_API_KEY` (or `GOOGLE_API_KEY`)

Optional model overrides:
- `CHATGPT_MODEL` (default: `gpt-5.2`)
- `GEMINI_MODEL` (default: `gemini-3-flash-preview`)
- `JUDGE_MODEL` (default: `gpt-4o`)
- `GEO_RUNS` (default: `1`, number of times to run each prompt)

Input from 1)
- queries.csv

Outputs from pipeline (raw responses)
- high_funnel_responses.csv
- mid_funnel_responses.csv
- low_funnel_responses.csv
- all_funnel_responses.csv (combined for DB storage)

Intermediate per-source tables (generated by pipeline)
- llm_table_view_combined_per_source.csv
- llm_table_view_high_per_source.csv
- llm_table_view_mid_per_source.csv
- llm_table_view_low_per_source.csv

Scoring outputs (generated by pipeline)
- geo_eval_results_combined.csv
- geo_eval_results_high.csv
- geo_eval_results_mid.csv
- geo_eval_results_low.csv
- *_summary.csv (per-file summaries)
- *_per_run.csv (per-run judged rows for caching)

Response-level scoring outputs (brand-focused)
- geo_response_eval_combined.csv
- geo_response_eval_high.csv
- geo_response_eval_mid.csv
- geo_response_eval_low.csv
- *_summary.csv (per-file summaries)
- *_per_run.csv (per-run scored rows for caching)

Sample Process in Excel: https://docs.google.com/spreadsheets/d/1XVaiBDICVBkp6wt4iGD2toqUSDJxESKtOp3LS1I5EFU/edit?gid=1556417993#gid=1556417993
